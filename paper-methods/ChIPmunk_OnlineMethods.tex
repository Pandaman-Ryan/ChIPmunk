\documentclass[12pt]{article}

% Imports
\usepackage{hyperref}
\usepackage[margin=0.5in]{geometry}
\usepackage{ctable}
\usepackage{array}
\usepackage{titlesec}

% Paragraph spacing
\setlength{\parindent}{0em}
\setlength{\parskip}{0.5em}

% Default font
\renewcommand*{\familydefault}{\sfdefault}

% title spacing
\titlespacing*{\section}
{0pt}{2pt}{0pt}
\titlespacing*{\subsection}
{0pt}{2pt}{0pt}

% table lines
\newcolumntype{?}{!{\vrule width 1pt}}

% hyperlinks
\hypersetup{
  breaklinks=true,  % so long urls are correctly broken across lines
  colorlinks=true,
  urlcolor=blue,
  linkcolor=red,
  citecolor=red,
 }

\begin{document}

\section*{Online Methods}

\subsection*{ChIPmunk model}

ChIPmunk models the shearing, pulldown, PCR, and sequencing steps of ChIP-seq and learns the parameters for each of these steps described in Table 1. 

\subsubsection*{Shearing}

Paired end

Paired end sequencing is the process of generating reads by sequencing both ends of the sequence fragment and thus allowing us to know the length of these fragments. Using this concept, we can take paired end ChIP sequencing data and read in fragment lengths at random points in the genome in order to find the gamma distribution that best models these lengths. In particular, the learn module reads in 10000 randomly selected fragment lengths from the inputted paired end bam file. These are filtered to remove error fragments that exceed the length $3 * \text{median}$. Using the fragment lengths can generate their mean, $\mu = \dfrac{\Sum_{i=1}^{n}X_i}{n}$. Now, using the method of moments: 
$$k\theta = \mu$$
$$k{\theta}^2 = \dfrac{1}{n}\Sum_{i=1}^n(X_i - \mu)^2$$  
Using these we can solve for $k$ and $\theta$ as $k = \dfrac{\mu}{\theta}$ and $\theta = \dfrac{1}{n\mu}\Sum_{i=1}^{n}(X_i - \mu)^2$
We can recreate the gamma distribution based off of these parameters learned and generate random fragment lengths that closely follow this distribution to use in simulator.

Questions: How did we figure out the fragements distribution aligns closest with the gamma dist?

Single end

To estimate the fragment length distribution from single-end reads, we assumed the length distribution followed gamma distribution with the mean value as $\mu$ and variance as $v$, and used reads located inside ChIP-seq peaks to estimate $\mu$ and $v$.

We processed a ChIP-seq peak at a time. For each read in a $peak_i$, we added its leftmost position into a list $\{start\}_{peak_i}$ if the read is on the forward strand, or its rightmost position into a list $\{end\}_{peak_i}$ if the read is on the reverse strand. The center point of this peak was calculated by equation (1)

$$center_{peak_i} = \frac{mean(\{start\}_{peak_i}) + mean(\{end\}_{peak_i})}{2}\;\;\;(1)$$

As is shown in equation (2) and (3), for every $peak_i$ we offset the coordinates in $\{start\}_{peak_i}$ and $\{end\}_{peak_i}$ by its center point, so that the coordinates of start points and end points were normalized and symmetric to zero. Then we concatenated the lists of all ChIP-seq peaks together to form $\{start\}$ and $\{end\}$. The mean value of fragment length mu can be estimated by formulation (4).

$$\{start\} = \oplus_{i=0}^{n} (\{start\}_{peak_i} - center_{peak_i})\;\;\;(2)$$
$$\{end\} = \oplus_{i=0}^{n} (\{end\}_{peak_i} - center_{peak_i})\;\;\;(3)$$
$$\mu = mean(\{end\}) - mean(\{start\})\;\;\;(4)$$

For both \{start\} and \{end\}, we calculated their probability density functions, cumulative density functions and expected density functions. Here, the expected density function $EDF(x)$ is defined as the expected deviation of a random element in the list to x, as is shown in (5) and (6) in which S is a random element in \{start\} and E is a random element in \{end\}
$$EDF_{start}(x) = E(|S - x|)\;\;\;(5)$$
$$EDF_{end}(x) = E(|E - x|)\;\;\;(6)$$

Since we have calculated $\mu$, we can reduce the density function of the fragment length distribution into $p_v(x)$. We constructed a score function for $v$ shown as equation (7)- (11). Intuitively, if we can have a correct guess of $v$, $F(v)$ should equals to zero. Thus, we conducted a binary search for $v$ between 1000 and 10000, and searched for the best $v$ that can minimize $|F(v)|$.

$$F(v) = E_v(|S + \frac{L}{2}|) + E_v(|E - \frac{L}{2}|) - E(|S + \frac{\mu}{2}|) + E(|E- \frac{\mu}{2}|)\;\;\;(7)$$
$$E_v(|S + L/2|) = \sum_{x=0}^\infty p_v(x) * EDF_{start}(-\frac{x}{2})\;\;\;(8)$$
$$E_v(|E - L/2|) = \sum_{x=0}^\infty p_v(x) * EDF_{end}(\frac{x}{2})\;\;\;(9)$$
$$E(|S + \frac{\mu}{2}|)=EDF_{start}(x)\;\;\;(10)$$
$$E(|E - \frac{\mu}{2}|)=EDF_{end}(x)\;\;\;(11)$$

In practice, we slightly offlist the last two items in (7) and changed it into (12), which provided us more accurate estimation for the variance of the fragment length distribution.
$$F(v) = E_v(|S + \frac{L}{2}|) + E_v(|E - \frac{L}{2}|) - E(|S + \frac{\mu}{2} - \frac{E- \frac{\mu}{2}}{4}|) - E(|E- \frac{\mu}{2} - \frac{S + \frac{\mu}{2}}{4}|)\;\;\;(12)$$


\subsubsection*{Pulldown}

**Go into math behind how we setup pulldown**

The pulldown step of the simulator represents purifying the precipitated DNA by washing away the sheared fragments that were not bound by the target protein or histone modification. These filtered fragments are then marked to be sequenced. The filtering process is not perfect and therefore some fragments not bound will also be pulled down to be sequenced which we label as noise. In order to model this process we start at a given position in the genome based on the region specified by the user. The random fragment is generated and based on its location we can generate its peak score. The peak score is a metric based on the peak intensity read from the bed file that the user inputted. The higher the intensity the higher the probability that a fragment will be mapped to that location. This isn't the only factor to determine if the fragment will be bound. Let $P_b$ be the probability of being bound. 
$P_b = \text{peak score} * P_{kept}$ where $P_{kept} = \dfrac{numreads * pcr_rate}{numfrags_per_run * numcopies}$

\subsubsection*{PCR}

\subsubsection*{Sequencing}

After all the fragments have been pulled down, it is time to generate the fastq reads through the sequencing process. At the start of this process we go through each fragment that was successfully pulled down and use its chromsome, start, and end positions to grab the sequence from the reference genome. If the sequencing method is paired end we take the first $n$ nucleotides, where $n$ is decided by the user input parameter readlen, and write out this read to the first fastq file. Then we take the reverse complement of the last $n$ nucleotides and output this to the second fastq file matching the index of the first. (Make sure to include read quality score)Otherwise if single end was specified, only the first $n$ nucleotides are outputted to a single a fastq. 

Do I need to specify the full output to the fastq files?

\subsection*{ChIPmunk implementation}

two modules
file formats
binning
C++, any special libraries we use, open source

\subsection*{Peak caller evaluation}

\subsection*{Data sources}


\end{document}
